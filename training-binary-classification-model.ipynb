{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8059972,"sourceType":"datasetVersion","datasetId":4754220},{"sourceId":8223411,"sourceType":"datasetVersion","datasetId":4875434},{"sourceId":8235711,"sourceType":"datasetVersion","datasetId":4884763},{"sourceId":8236309,"sourceType":"datasetVersion","datasetId":4885203},{"sourceId":8258775,"sourceType":"datasetVersion","datasetId":4901470},{"sourceId":8258795,"sourceType":"datasetVersion","datasetId":4901484},{"sourceId":8265430,"sourceType":"datasetVersion","datasetId":4906548},{"sourceId":8265453,"sourceType":"datasetVersion","datasetId":4906567},{"sourceId":8268190,"sourceType":"datasetVersion","datasetId":4908537},{"sourceId":8274576,"sourceType":"datasetVersion","datasetId":4913339},{"sourceId":8274622,"sourceType":"datasetVersion","datasetId":4913376},{"sourceId":8277862,"sourceType":"datasetVersion","datasetId":4915601},{"sourceId":8278026,"sourceType":"datasetVersion","datasetId":4915713},{"sourceId":8278077,"sourceType":"datasetVersion","datasetId":4915757},{"sourceId":8278933,"sourceType":"datasetVersion","datasetId":4916419}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip install metric-learn\nimport pandas as pd\nimport numpy as np\nimport pickle\nimport matplotlib.pyplot as plt\nfrom metric_learn import MMC\nfrom sklearn.neighbors import KDTree\nfrom sklearn.preprocessing import MinMaxScaler\nimport time\nimport ast\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-08T04:52:02.462736Z","iopub.execute_input":"2024-05-08T04:52:02.463072Z","iopub.status.idle":"2024-05-08T04:52:15.694845Z","shell.execute_reply.started":"2024-05-08T04:52:02.463044Z","shell.execute_reply":"2024-05-08T04:52:15.693979Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting metric-learn\n  Downloading metric_learn-0.7.0-py2.py3-none-any.whl.metadata (5.2 kB)\nRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from metric-learn) (1.26.4)\nRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from metric-learn) (1.11.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from metric-learn) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->metric-learn) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->metric-learn) (3.2.0)\nDownloading metric_learn-0.7.0-py2.py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: metric-learn\nSuccessfully installed metric-learn-0.7.0\n","output_type":"stream"}]},{"cell_type":"code","source":"#MONDAY AT HOSTEL\n\n# Record start time\nstart_time = time.time()\n\n# Define the file path of the CSV file containing the input data\ninput_file_path = '/kaggle/input/10k-3lakh-rows/RecoOutPileup_uniform_1_10000_16666_ns.root_recohits.csv'\n\n# Read the original CSV file with all columns\noriginal_data = pd.read_csv(input_file_path)\n\n# Select only the desired columns (x, y, z, t)\ninput_data_1 = original_data[['x', 'y', 'z', 't']]\n\n# Scale the data\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(input_data_1)\n\n# Load the trained MMC model from the pickle file\nmodel_file_path = '/kaggle/input/mmc-scaled-model-pkl/mmc_model_scaled.pkl'\nwith open(model_file_path, 'rb') as file:\n    trained_mmc_model = pickle.load(file)\n\n# Transform the input data using the trained MMC model\nX_transformed = trained_mmc_model.transform(scaled_data)\n\n# KDTree\ntree = KDTree(X_transformed, leaf_size=2)\n\n# Find neighbors\nneighbors_list = []\nfor i in range(len(X_transformed)):\n    neighbors = tree.query_radius(X_transformed[i].reshape(1, -1), r=0.01)[0]\n    neighbors_list.append(neighbors)\n\n# Initialize lists to store data for CSV\npoint1_list = []\npoint2_list = []\ndelta_z_values = []\ndelta_t_values = []\nlabels = []\n\n# Randomly select pairs of point indices from the embedded space\nrandom_indices = np.random.choice(len(X_transformed), size=375913, replace=False)\nfor i in random_indices:\n    j = np.random.choice(neighbors_list[i])\n    if i != j:\n        point1_csv = X_transformed[i]  # Store the actual value of point 1\n        point2_csv = X_transformed[j]  # Store the actual value of point 2\n        \n        # Extract z and t values for point 1 and point 2\n        z1 = original_data.iloc[i]['z']\n        z2 = original_data.iloc[j]['z']\n        t1 = original_data.iloc[i]['t']\n        t2 = original_data.iloc[j]['t']\n        \n        # Calculate delta z and delta t\n        delta_z = abs(z2 - z1)\n        delta_t = abs(t2 - t1)\n        \n        # Normalize delta z and delta t\n        max_delta_z = original_data['z'].max()\n        max_delta_t = original_data['t'].max()\n        \n        print(\"Max delta z value:\", max_delta_z)\n        print(\"Max delta t value:\", max_delta_t)\n        \n        normalized_delta_z = delta_z / max_delta_z\n        normalized_delta_t = delta_t / max_delta_t\n        \n        # Check if muonid is -999 for either point 1 or point 2\n        if original_data.iloc[i]['muonid'] == -999 or original_data.iloc[j]['muonid'] == -999:\n            # If muonid is -999 for either point 1 or point 2, assign label 0\n            label = 0\n        else:\n            # Assign label based on muon IDs\n            if original_data.iloc[i]['muonid'] == original_data.iloc[j]['muonid']:\n                label = 1\n            else:\n                label = 0\n        \n        # Append data to lists\n        point1_list.append(point1_csv)\n        point2_list.append(point2_csv)\n        delta_z_values.append(normalized_delta_z)\n        delta_t_values.append(normalized_delta_t)\n        labels.append(label)\n\n# Create DataFrame from the lists\ndata = pd.DataFrame({\n    'point1': point1_list,\n    'point2': point2_list,\n    'normalized_delta_z': delta_z_values,\n    'normalized_delta_t': delta_t_values,\n    'label': labels\n})\n\n# Save DataFrame to CSV\ndata.to_csv('p1_p2_normalized_dz_dt_label.csv', index=False)\n\n# Calculate execution time\nexecution_time = time.time() - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the CSV file containing point 1, point 2, delz, delt and label\ndata = pd.read_csv('/kaggle/input/p1-p2-normalized-dz-dt-label/p1_p2_normalized_dz_dt_label.csv')\n\n# Count the number of rows with label 1\nnum_label_1 = (data['label'] == 1).sum()\n\n# Select rows with label 0\ndata_label_0 = data[data['label'] == 0]\n\n# Sample the same number of rows with label 0 as there are rows with label 1\ndata_label_0_sampled = data_label_0.sample(n=num_label_1, random_state=42)\n\n# Concatenate the sampled rows with the rows with label 1\nbalanced_data = pd.concat([data[data['label'] == 1], data_label_0_sampled])\n\n# Save the balanced data to a new CSV file\nbalanced_data.to_csv('P1_P2_delz_delt_balanced_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-29T04:33:31.454560Z","iopub.execute_input":"2024-04-29T04:33:31.455092Z","iopub.status.idle":"2024-04-29T04:33:35.297204Z","shell.execute_reply.started":"2024-04-29T04:33:31.455059Z","shell.execute_reply":"2024-04-29T04:33:35.295695Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load your CSV file into a DataFrame\ndf = pd.read_csv('/kaggle/input/p1-p2-delz-delt-balanced-data/P1_P2_delz_delt_balanced_data.csv')\n\n# # Remove square brackets and convert string representation to numerical values\n# df['point1'] = df['point1'].str.replace('[','').str.replace(']','').str.split().apply(lambda x: [float(i) for i in x])\n# df['point2'] = df['point2'].str.replace('[','').str.replace(']','').str.split().apply(lambda x: [float(i) for i in x])\n\n# # Expand the lists into separate columns\n# df[['point1_x', 'point1_y', 'point1_z', 'point1_w']] = pd.DataFrame(df['point1'].tolist(), index=df.index)\n# df[['point2_x', 'point2_y', 'point2_z', 'point2_w']] = pd.DataFrame(df['point2'].tolist(), index=df.index)\n\n# Select features and target variable\nX = df[['normalized_delta_z', 'normalized_delta_t']]\ny = df['label']\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Instantiate the Random Forest Classifier model\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Save the trained model as a pickle file\nmodel_file_path = 'random_forest_model.pkl'\nwith open(model_file_path, 'wb') as file:\n    pickle.dump(model, file)\n\n\n# Predict on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T05:00:21.627467Z","iopub.execute_input":"2024-05-06T05:00:21.627942Z","iopub.status.idle":"2024-05-06T05:00:37.141588Z","shell.execute_reply.started":"2024-05-06T05:00:21.627907Z","shell.execute_reply":"2024-05-06T05:00:37.140195Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Accuracy: 0.9514143813431224\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/p1-p2-delz-delt-balanced-data/P1_P2_delz_delt_balanced_data.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-05-10T06:18:40.800952Z","iopub.execute_input":"2024-05-10T06:18:40.801347Z","iopub.status.idle":"2024-05-10T06:18:42.944948Z","shell.execute_reply.started":"2024-05-10T06:18:40.801315Z","shell.execute_reply":"2024-05-10T06:18:42.943798Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"                                                   point1  \\\n0       [ 0.00000000e+00  1.58390412e-09 -1.42912189e-...   \n1       [ 0.00000000e+00  9.54720582e-10 -3.13231902e-...   \n2       [ 0.00000000e+00  1.18881360e-09 -3.01737383e-...   \n3       [ 0.00000000e+00  1.46466857e-09 -5.41194863e-...   \n4       [ 0.00000000e+00  1.70874001e-09 -3.47229801e-...   \n...                                                   ...   \n115767  [ 0.00000000e+00  7.44388911e-10 -2.46969985e-...   \n115768  [ 0.00000000e+00  1.60458108e-09 -2.47747157e-...   \n115769  [ 0.00000000e+00  1.73603686e-09 -1.78714268e-...   \n115770  [ 0.00000000e+00  8.69509109e-10 -3.88770566e-...   \n115771  [ 0.00000000e+00  6.12500810e-10 -6.69541097e-...   \n\n                                                   point2  normalized_delta_z  \\\n0       [ 0.00000000e+00  1.42632785e-09 -1.52226668e-...            0.048577   \n1       [ 0.00000000e+00  8.50653766e-10 -3.16910046e-...            0.014416   \n2       [ 0.00000000e+00  1.18872954e-09 -2.99909109e-...            0.008223   \n3       [ 0.00000000e+00  1.53864207e-09 -5.49883296e-...            0.004805   \n4       [ 0.00000000e+00  1.58402017e-09 -3.44027720e-...            0.010572   \n...                                                   ...                 ...   \n115767  [ 0.00000000e+00  1.61757497e-09 -2.54066730e-...            0.071118   \n115768  [ 0.00000000e+00  1.74989379e-09 -2.44185161e-...            0.020182   \n115769  [ 0.00000000e+00  1.55962921e-09 -1.72207712e-...            0.094183   \n115770  [ 0.00000000e+00  1.86416701e-09 -3.56531680e-...            0.002883   \n115771  [ 0.00000000e+00  8.30003581e-10 -6.68292701e-...            0.025948   \n\n        normalized_delta_t  label  \n0                 0.000090      1  \n1                 0.000045      1  \n2                 0.000000      1  \n3                 0.000045      1  \n4                 0.000000      1  \n...                    ...    ...  \n115767            0.000361      0  \n115768            0.000090      0  \n115769            0.002255      0  \n115770            0.000180      0  \n115771            0.000902      0  \n\n[115772 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>point1</th>\n      <th>point2</th>\n      <th>normalized_delta_z</th>\n      <th>normalized_delta_t</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[ 0.00000000e+00  1.58390412e-09 -1.42912189e-...</td>\n      <td>[ 0.00000000e+00  1.42632785e-09 -1.52226668e-...</td>\n      <td>0.048577</td>\n      <td>0.000090</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[ 0.00000000e+00  9.54720582e-10 -3.13231902e-...</td>\n      <td>[ 0.00000000e+00  8.50653766e-10 -3.16910046e-...</td>\n      <td>0.014416</td>\n      <td>0.000045</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[ 0.00000000e+00  1.18881360e-09 -3.01737383e-...</td>\n      <td>[ 0.00000000e+00  1.18872954e-09 -2.99909109e-...</td>\n      <td>0.008223</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[ 0.00000000e+00  1.46466857e-09 -5.41194863e-...</td>\n      <td>[ 0.00000000e+00  1.53864207e-09 -5.49883296e-...</td>\n      <td>0.004805</td>\n      <td>0.000045</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[ 0.00000000e+00  1.70874001e-09 -3.47229801e-...</td>\n      <td>[ 0.00000000e+00  1.58402017e-09 -3.44027720e-...</td>\n      <td>0.010572</td>\n      <td>0.000000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115767</th>\n      <td>[ 0.00000000e+00  7.44388911e-10 -2.46969985e-...</td>\n      <td>[ 0.00000000e+00  1.61757497e-09 -2.54066730e-...</td>\n      <td>0.071118</td>\n      <td>0.000361</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>115768</th>\n      <td>[ 0.00000000e+00  1.60458108e-09 -2.47747157e-...</td>\n      <td>[ 0.00000000e+00  1.74989379e-09 -2.44185161e-...</td>\n      <td>0.020182</td>\n      <td>0.000090</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>115769</th>\n      <td>[ 0.00000000e+00  1.73603686e-09 -1.78714268e-...</td>\n      <td>[ 0.00000000e+00  1.55962921e-09 -1.72207712e-...</td>\n      <td>0.094183</td>\n      <td>0.002255</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>115770</th>\n      <td>[ 0.00000000e+00  8.69509109e-10 -3.88770566e-...</td>\n      <td>[ 0.00000000e+00  1.86416701e-09 -3.56531680e-...</td>\n      <td>0.002883</td>\n      <td>0.000180</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>115771</th>\n      <td>[ 0.00000000e+00  6.12500810e-10 -6.69541097e-...</td>\n      <td>[ 0.00000000e+00  8.30003581e-10 -6.68292701e-...</td>\n      <td>0.025948</td>\n      <td>0.000902</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>115772 rows × 5 columns</p>\n</div>"},"metadata":{}}]}]}